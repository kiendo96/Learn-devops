Câu chuyện về việc triển khai Statefulset/Database trên Kubernetes (K8S)
K8S có thể giúp chạy các ứng dụng như Web Service hoặc Stateless hoặc các dạng ứng dụng chỉ cần Ephermeral Storage rất ổn định, scale nhanh chóng. Tuy nhiên các ứng dụng khi triển khai lên Cloud hoặc Private Cloud sẽ ưu tiên chạy Database hoặc các ứng dụng cần lưu trữ file ra thành các VM riêng biệt hoặc thậm chí là Server dạng Dedicated theo truyền thống, vì người ta lo sợ việc chạy DB trên K8S mang đến rủi ro / tính ổn định / và hiệu suất (performance) sẽ bị giảm. Nhưng liệu bạn có dám thử để chạy loại ứng dụng "khó xơi" này trên K8S ? Mình muốn chia sẻ một chút như sau.
Deploy DB trên K8S như nào ?

Khi học K8S, ta sẽ thấy các Manifest YAML statefulset hoặc deploy để deploy một số DB cơ bản như MySQL chẳng hạn, một cái Manifest khai báo image tới mysql, chạy và sử dụng, tuy nhiên khi ta scale nó lên 2 lên 3, mysql sẽ không biến thành cluster gì cả, nó sẽ hiểu là sinh ra thêm 2 hoặc 3 node db riêng biệt. Để deploy được DB Cluster trên K8S, phải sử dụng Helm Chart, Operator hoặc tự viết rất nhiều configmap / init script liên quan thì mới làm được.
StatefulSet Resource

Trong K8S, StatefulSet giúp định nghĩa một Pod template mà có thể scale như Deployment, điểm khác biệt đó là Pod được sinh ra sẽ luôn có thứ tự là 1, 2, 3, 4 ... và khi scale down thì nó sẽ đi -4, -3, -2, -1 có thứ tự. Điều này sẽ đúng với đa số các loại Database hiện tại, đó là gần như chỉ có thể scale-out, còn việc scale-in thì sẽ khá là khó khăn, ví dụ với 4 pod như trên, ta không thể xóa Pod (node) 1 được, mà phải xóa từ Node 4, rồi 3, rồi 2, xong mới đến 1 được. StatefulSet có thêm một trường gọi là là VolumeClaimTemplate, giúp từng Pod được tạo ra sẽ có một PVC riêng biệt cùng tên, cùng index suffix với nó để attach đồng bộ, cái này sẽ giúp triển khai DB app tốt hơn so với Deployment, giúp Pod + Disk luôn ăn khớp với nhau.
Ephemeral Storage (EmptyDir)

Đây là loại Storage có tính chất tạm thời, có thể lưu trên Disk hoặc RAM tùy vào cấu hình, nếu Pod sử dụng EmptyDir Volume, khi Pod bị xóa và tạo lại, EmptyDir Volume sẽ biến mất và thay bằng cái mới, đồng nghĩa với việc dữ liệu sẽ bay theo, bất kể là lưu trên RAM hay Disk, còn nếu Pod bị Restart, volume vẫn sẽ tồn tại và dữ liệu chưa bị mất đi. Loại Storage này thích hợp với một số Inmemory DB như Redis chẳng hạn, hoặc sử dụng để chứa temp log cho DB app, chứa dữ liệu khởi tạo ứng dụng.
Headless Service

Là Service trong K8S, tuy nhiên Service này sẽ không có IP, ta sẽ làm nó bằng cách tạo Service mode ClusterIP như bình thường, nhưng sẽ set trường .spec.clusterIP bằng None, lúc này Service sẽ không tạo ra EndpointSlice tới các Pod, khi phân giải Service Name thì nó sẽ cho ra IP (bản ghi A) của các Pod luôn, kube-proxy sẽ không handle việc traffic đi qua đi lại trong Pod, nếu ở bên trong Pod gọi Pod qua Headless Service, điều này giống với việc gọi thẳng IP của Pod vậy. Mode này sinh ra cực kỳ hữu ích, giúp các Pod có khả năng Discover lẫn nhau, tất nhiên là bản thân Database App sẽ không làm việc này, mà bên trong Pod, người ta sẽ cấy script khởi tạo và get ip của các Pod khác dựa vào Headless Service, từ đó tự biết mà cấu hình Cluster tới nhau. Ngoài ra về traffic data, ta sẽ có khả năng giống như việc tương tác thẳng với Database Node, tránh các trường hợp như kiểu NAT issue, Proxied issue. gần như là 99% DB app chạy trên K8S sẽ phải dùng Headless Service, việc không phải đi qua kube-proxy cũng giúp performance cải thiện cực kỳ đáng kể.
Container Image

Database thường có cấu hình không phức tạp, nhưng phải "chuẩn", phải đồng bộ tham số, nhưng lại không giống nhau hoàn toàn, ví dụ khi cấu hình Redis Cluster hoặc Etcd, nếu tạo một Configmap chứa Cluster Node = Pod A, Pod B, Pod C và apply trên toàn bộ 3 Pod sẽ là không được. Phải khai báo configmap của từng Pod khác nhau, trên Pod A thì là Cluster Node = Pod B, Pod C, trên Pod B thì là Cluster Node = Pod A, Pod C ... để từng Pod (node) hiểu rằng nó cần phải được peer tới những Node khác trong Cluster là IP/Host bao nhiêu ?

Trên Docker Hub, có thể thấy rất nhiều các Image do Docker Offical maintain, tuy nhiên toàn bộ sẽ chỉ chạy được mode Single, không hỗ trợ script khởi tạo, healthcheck, auto config cluster. Nghĩa là nếu ta chạy các Image trên Docker Offical mà muốn cấu hình Cluster, ta buộc phải mount config giống như việc cài đặt DB truyền thống trên VM như trước, chỉ thích hợp để chạy Test/CICD hoặc Single Host. Còn khi mà chạy DB trên K8S, ta cũng vẫn phải sử dụng Docker Image mà thôi, nhưng sẽ dùng Image được thiết kế riêng cho K8S, cho Helm, cho Operator, các Image này được gắn các script, agent hoặc một app nhỏ ở bên trong giúp khởi tạo, kết nối với các Pod DB khác trong Cluster, kết nối tới Operator Controller, kết nối với K8S API. Rất nhiều kịch bản gắn trong đó cùng với script phức tạo đi kèm. Nói chung là phải chọn Image phù hợp, ví dụ Helm chart Elasticsearch của Bitnami được thiết kế Image riêng, Helm Chart và Operator của Elasticsearch do Elastic maintain cũng được thiết kế Image riêng, sử dụng khác image là sẽ không chạy được.
Storage Class/PVC

Tuyệt đối không sử dụng File Network Storage như NFS cho các DB app, nguyên nhân thì quá dễ hiểu => chậm, ví network kiểu gì cũng có độ trễ chậm, không thích hợp để ghi file liên tục như DB. Bắt buộc phải sử dụng Block Storage, ví dụ EKS -> EBS, Azure -> Azure Disk, GCP -> GKE-PD. Block Storage là một Disk riêng biệt được tạo ra cho riêng Pod đó, chỉ hỗ trợ mode là RWO hoặc RWPO, hạ tầng K8S bắt buộc phải hỗ trợ Dynamic Block Storage. Nếu trên Cloud thì có sẵn rồi, còn OnPrem thì phải cải tiến, cài đặt CSI giúp tích hợp K8S với infrastructure ở dưới để hỗ trợ StorageClass + PVC block storage.
Sizing Worker Node

Ví dụ bạn có một K8S Cluster gồm 6 node, ta sẽ quy hoạch DB app chạy trên đều cả 6 node ? cấu hình Pod Antifinty, đặt Resource Constraint ? Cái này sai nhé, phải cấu hình như này.

Ta được yêu cầu cài một cụm Redis Sentinel, gồm 3 Node Redis (3 pod), dev lead yêu cầu mỗi node là 32gb ram, 8 cpu. Ta sẽ tạo NodeGroup là "RedisForDev" chẳng hạn, gồm min = 3 worker node, max >= 3. Đặt taint noschedule và label để dedicate node này, tránh các Pod không có toleration chui được vào các Node này. Sau đó trên Helm hoặc Operator cài đặt Redis, ta cấu hình các thông số sau: Tolerations: vào đúng taint của nodegroup kia, NodeAntiAffinity + PodAffinity mode Hard để scale một Pod Redis sẽ chỉ được nằm trên một Worker Node, Resource thì bỏ đi không cần set, vì mỗi Pod một Node riêng thì chả cần Resource Constraint làm gì cả. Cách scale này rất hiệu quả và ổn định, vì DB thì ăn RAM với CPU cực nhiều, ta nên dedicate mỗi Pod một Node để đảm bảo hiệu suất tốt nhất.
Sử dụng PodDisruptionBudget (PDB)

Tính năng này phù hợp cho DB/Statefulset app, worker của K8S trong trường hợp bị replace, bị scale-in hoặc bị thay thế như kiểu nâng cấp size chẳng hạn, trước đó nó sẽ phải Draint / Cordon rồi delete Node, điều này sẽ trực tiếp làm ảnh hưởng Pod đang chạy, mà riêng DB thì việc bị Reboot là cực kỳ cấm kỵ, NodeGroup đang là 3 node size M5.large, tôi tăng node group lên M5.xlarge chẳng hạn, nhỡ chẳng may nó replace hết toàn bộ node cùng một lúc, cả 3 pod chạy 3 node đều chết -> downtime, PDB sinh ra giúp giữ Pod không bị Drain ngay lập tức, Drain là quá trình "rút" các Pod ra khỏi Node, kiểu một dạng pre-maintain. Để Node bị Drain khi Node chứa Pod có PDB, thì ta sẽ phải chủ động kill Pod đó và đợi Pod lên, hoặc force drain node. Đa phần nếu bằng Helm thì trong Helm Chart của nhiều app sẽ có sẵn hết resource này để giúp tính HA cao hơn.
Helm và Operator

Helm sinh ra giúp deploy và tổng hợp các resource K8S thành một package application, Bitnami là một provider đi đầu trong việc cung cấp các DB helm chart, loại nào cũng có, mode nào cũng có. Nhưng về sau người ta phát triển thêm Operator để làm việc này. Thực tế thì Operator sẽ dựa vào CRD + Controller Operator, ta chỉ cần khai báo đúng CRD spec là được. Việc sử dụng Operator CRD nói thật là sẽ khó khăn hơn so với Helm Chart, nhất là Chart của Bitnami support tận răng nhiều tham số. Vậy lựa chọn như nào ?

Có một số thứ Helm chart sẽ tốt hơn, đầu tiên là nhanh, thứ hai là config/architecture của Helm Chart + cách build image thông minh. Ví dụ Elasticsearch, mình sẽ chọn Helm từ Bitnami, Redis thì chọn Helm từ dandydev. Elasticsearch helm chart của Bitnami thiết kế cực đơn giản nhưng hiệu quả, Chart giúp chia ra mô hình Node Role sẵn có như Coordinating/Master/Data/Ingest. Còn Redis Chart thì cài cắm rất nhiều kịch bản giúp tránh việc bị Split-Brain khi chạy Cluster.

Operator thì tùy vào cộng đồng cũng như nhà phát triển DB đó, ví dụ Redhat có sản phẩm Strimzi Operator cho Kafka, dùng cực kỳ ổn định, dễ sử dụng, TiDB thì có TiDB controller. Thực tế thì Operator cực kỳ phức tạp, ngoài việc điều khiển deploy Pod bên ngoài K8S, Controller của Operator sẽ điều khiển về mặt dữ liệu, cấu hình của DB, DB khi bị restart, được nâng cấp version, cần refresh cache data, Controller sẽ được thiết kế để làm những việc này một cách tự động, ngoài ra chúng cũng monitor các DB node tự động và tự ra quyết định restart, join cluster, ngắt kết nối tránh Split-Brain khi cần thiết, tự config TLS, authen generator, và vô số chức năng khác chỉ bằng việc khai báo spec trên CRD.
Update DB ?

Chỉ cần tuân theo đúng guide của hãng là được, nếu dùng Helm Chart thì hơi lấn cấn và phải đọc kỹ tài liệu, còn dùng Operator thì đa số hỗ trợ cực kỳ tốt về cái này.
K8S Lease

Lease là một loại resource mới của K8S, K8S có default lease, nhưng cũng có cả CRD (custom lease). Chức năng của Lease đó là giải quyết vấn đề Split-Brain, Singleton. Đa phần liên quan tới việc bầu chọn master node. Hiểu nôm na đó là ta có 3 node làm master (multi-master). Có thể đi vào 1 trong 3 đều được, nhưng khi có sự thay đổi về master node nào đó, ví dụ một node bị restart đi, lease sẽ giúp traffic chuyển hướng, hoặc ngắt traffic ngay lập tức nếu không đủ tối thiểu 2/3 node còn lại đang ready. Tính năng này chủ yếu bảo vệ việc đọc/ghi node khi upgrade/restart/maintain, vừa zero-downtime nhưng cũng đảm bảo tính "consistency". Kiểm tra nếu resource chứa Lease tức là độ tin cậy của Cluster đã cộng thêm điểm rồi đó nha.
Split-Brain là gì ?

Về nguyên lý cơ bản của Cluster, bao gồm shard/replicate, để hiểu được SB là gì, ta phải tính đơn vị nhỏ nhất của DB đó là "một record value". SB liên quan chủ yếu về write-mode, tức các câu lệnh liên quan tới thêm/sửa/xóa bản ghi, hay còn gọi là DML, ví dụ có 3 node Redis Sentinel, một record sẽ luôn chỉ ghi vào một node, record thứ hai có thể vào node khác, record thứ 3, thứ 4, cũng vậy

-> Mỗi record được phân bố đều ra các Node -> ta gọi đó là Shard.
-> Mỗi record được ghi vào một Node sau đó lại được copy chính record đó ra một Node khác -> ta gọi đó là Replica.

Cả bản ghi trên Shard và Rep đều có vị trí và chức năng của nó, record A trên Node A sẽ là primary record (vừa đọc vừa ghi được), rep của nó là A.1 đi -> lưu trên Node B sẽ được gọi là backup record (chỉ đọc). Do thiết kế của Role Node, vì Node A là primary nên record trên Node đó nếu muốn tác động thêm sửa xóa phải đi qua Node A trước, sau đó nó mới replicate tới node B, còn Node B chỉ là secondary node, tạm thời nhé, nó chỉ có thể đọc, GET/SELECT.

Nếu ta cố tình ghi vào secondary node hoặc hệ thống tự động promote secondary node lên thành primary node trong trường hợp node A (primary) đang có sự cố/bị down. Sau khi ta up lại node A, dữ liệu A và B không đồng nhất -> điều này do split brain gây nên, split brain xảy ra chủ yếu cho việc quá trình healthcheck, promote primary node không đồng nhất, dẫn tới bị tranh chấp trạng thái, không đồng nhất dữ liệu replicate giữa các node. Gây mất tính nhất quán của dữ liệu. Google để biết chi tiết rất nhiều bài nói về cái này.
Có scale-in (reduce) node được không ?

Đa số database được thiết kế để chỉ có thể mở rộng thêm, còn việc giảm node khá ít, rủi ro cao. Hơn nữa do thiết kế StatefulSet chỉ thao tác thêm/xóa node ở index cuối nên rất bất tiện. Đấy là về lý thuyết, còn thực tế thì tùy vào ứng dụng đó được thiết kế lưu trữ dữ liệu như nào ?

Đối với một số DB như Elasticsearch, để reduce được node -> làm được, tuy nhiên phải chủ động archive/index lại dữ liệu bên trong trước bằng tay. Còn như Kafka/TiDB thì cũng vậy, nhưng chúng có hẳn tool để làm việc này, nguyên lý của việc reduce node đó là phải move hết dữ liệu sang node khác, làm cho node đó vẫn ở cluster mode nhưng không chứa bất cứ bản ghi nào, còn nếu xóa node khỏi cluster khi nó vẫn còn data thì hậu quả mất dữ liệu sẽ rất lớn, thậm chí gây chết Cluster. Tốt nhất là research cách để move data và đảm bảo node đó = 0% usage disk là được.
Performance?

Việc chạy Container DB thì hiệu suất chắc chắn là giảm, cái này không tránh được. Ví dụ Elasticsearch và Kafka, đây là hai loại DB app mà mình thấy khả năng chạy trên K8S cũng như Cluster của nó cực kỳ ổn định, nhưng vì viết bằng Scala và Java nên hiệu suất sẽ bị bóp 1 chút, vì bản chất Java là JVM, còn phải đi qua container runtime nữa. Để giải quyết bài toán này, có 1 số công ty startup quyết định code lại bằng một ngôn ngữ lập trình có tính biên dịch, native mới machine code nhất, như Rust hoặc C. Ví dụ Redpanda họ code lại Kafka bằng C++ hoàn toàn, không fork bất cứ cái gì từ source kafka gốc trên Apache. Tuy nhiên ta vẫn có thể dùng Kafka nguyên thủy, hay kể cả các loại DB khác chạy trên Container/K8S mà loại bỏ vấn đề này.

Đó là chọn CPU type + chọn hoặc điều chỉnh Disk IOPS cao hơn. CPU chọn type mới nhất càng tốt hoặc chuyển sang sử dụng thử CPU kiến trúc mới như ARM, AWS Graviton chẳng hạn. Disk IOPS cố gắng đẩy lên cao nhất, tùy vào cost, nhưng mượt nhất thì cứ 15k trở lên là được, Kafka mình chạy trên SAN disk IOPS rơi vào khoảng 40000 - 60000, vì là SAN disk có nhiều máy ảo cùng sử dụng disk nên sẽ rơi vào khoảng chứ không chính xác con số được. khoảng IOPS trên thì app đọc và xử lý kafka message khoảng gần 100.000 record / giây, con số khá là lớn.
Documents

Cuối cùng là phải định nghĩa được cấu trúc của loại DB đó, cách hoạt động, cách lưu trữ, cơ cấu tổ chức dữ liệu, cluster, shard, replicate như thế nào, cách cấu hình như nào ? Data lưu ở đâu ? RAM hay Disk, phân phối như nào ? Chịu tải được bao nhiêu kết nối, truy vấn dữ liệu. Sizing RAM/CPU/IOPS là bao nhiêu. Cần phải nắm vững những khái niệm cơ bản này trước. Tuyệt đối không sử dụng vội các manifest có sẵn, sử dụng Helm ngay lập tức mà chưa nghiên cứu kiến trúc của loại DB đó, có thể deploy thử nghiệm dần, việc triển khai DB trên K8S ngoài việc nhanh ra thì các kịch bản Helm, Operator giúp ta hiểu được kiến trúc, công việc của DB app cực kỳ nhanh, thay vì lên mạng loay hoay kiếm cách cài đặt, người ta định nghĩa sẵn script / code base xử lý việc gen ra cấu hình sẵn rồi, chỉ cần đọc và hiểu là được, có thể sửa nếu thấy chưa phù hợp.
Một vài chia sẻ nhỏ, bài hơi dài, mọi người cho xin thêm ý kiến nhé.